{"cells":[{"cell_type":"code","source":["import sys\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\n\nssc = StreamingContext(sc, 5)#creando la sesion de spark streaming\n\nlines = ssc.socketTextStream(\"localhost\",9999)\n\nwords = lines.flatMap(lambda x: x.split(\" \"))\\\n                .map(lambda x: (x,1))\\\n                .reduceByKey(lambda x,y: x + y)\n# Almacenar los datos transformados en HDFS\nwords.foreachRDD(lambda rdd: rdd.saveAsTextFile(\"/ruta/de/almacenamiento/en/hdfs\"))    \n#words\nwords.pprint()\n    \n\n#ssc.stop(stopSparkContext=True, stopGraceFull=True)\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6c9bc9d4-dc59-4091-ac83-e670c332f0ba","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%fs ls /ruta/de/almacenamiento/en/hdfs"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"06829ccd-97e3-48e6-9b4d-0df19bf4ce20","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/ruta/de/almacenamiento/en/hdfs/_SUCCESS","_SUCCESS",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00000","part-00000",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00001","part-00001",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00002","part-00002",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00003","part-00003",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00004","part-00004",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00005","part-00005",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00006","part-00006",0,1688942729000],["dbfs:/ruta/de/almacenamiento/en/hdfs/part-00007","part-00007",0,1688942729000]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00000</td><td>part-00000</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00001</td><td>part-00001</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00002</td><td>part-00002</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00003</td><td>part-00003</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00004</td><td>part-00004</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00005</td><td>part-00005</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00006</td><td>part-00006</td><td>0</td><td>1688942729000</td></tr><tr><td>dbfs:/ruta/de/almacenamiento/en/hdfs/part-00007</td><td>part-00007</td><td>0</td><td>1688942729000</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"758cec66-0d12-495a-bb06-a168f3180d93","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mParseException\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-3232893737865031>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tabla \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhdfs://ruta/de/almacenamiento/en/hdfsa\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:473\u001B[0m, in \u001B[0;36mDataFrameReader.table\u001B[0;34m(self, tableName)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtable\u001B[39m(\u001B[38;5;28mself\u001B[39m, tableName: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m    441\u001B[0m \n\u001B[1;32m    442\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.4.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;124;03m    >>> _ = spark.sql(\"DROP TABLE tblA\")\u001B[39;00m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtableName\u001B[49m\u001B[43m)\u001B[49m)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mParseException\u001B[0m: \n[PARSE_SYNTAX_ERROR] Syntax error at or near ':'.(line 1, pos 4)\n\n== SQL ==\nhdfs:ruta/de/almacenamiento/en/hdfs/\n----^^^\n","errorSummary":"<span class='ansi-red-fg'>ParseException</span>: \n[PARSE_SYNTAX_ERROR] Syntax error at or near ':'.(line 1, pos 4)\n\n== SQL ==\nhdfs:ruta/de/almacenamiento/en/hdfs/\n----^^^\n","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n","\u001B[0;31mParseException\u001B[0m                            Traceback (most recent call last)\n","File \u001B[0;32m<command-3232893737865031>:1\u001B[0m\n","\u001B[0;32m----> 1\u001B[0m tabla \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhdfs://ruta/de/almacenamiento/en/hdfsa\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n","\n","File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n","\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n","\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n","\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n","\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n","\u001B[1;32m     51\u001B[0m     )\n","\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n","\n","File \u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py:473\u001B[0m, in \u001B[0;36mDataFrameReader.table\u001B[0;34m(self, tableName)\u001B[0m\n","\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtable\u001B[39m(\u001B[38;5;28mself\u001B[39m, tableName: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n","\u001B[1;32m    440\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001B[39;00m\n","\u001B[1;32m    441\u001B[0m \n","\u001B[1;32m    442\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.4.0\u001B[39;00m\n","\u001B[0;32m   (...)\u001B[0m\n","\u001B[1;32m    471\u001B[0m \u001B[38;5;124;03m    >>> _ = spark.sql(\"DROP TABLE tblA\")\u001B[39;00m\n","\u001B[1;32m    472\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n","\u001B[0;32m--> 473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jreader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtableName\u001B[49m\u001B[43m)\u001B[49m)\n","\n","File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n","\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n","\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n","\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n","\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n","\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n","\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n","\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n","\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n","\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n","\n","File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n","\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n","\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n","\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n","\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n","\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n","\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n","\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n","\n","\u001B[0;31mParseException\u001B[0m: \n","[PARSE_SYNTAX_ERROR] Syntax error at or near ':'.(line 1, pos 4)\n","\n","== SQL ==\n","hdfs:ruta/de/almacenamiento/en/hdfs/\n","----^^^\n"]}}],"execution_count":0},{"cell_type":"code","source":["    ssc.start()\n    ssc.awaitTermination()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"a0841671-51a4-4c41-8409-f4dd8b69ab1d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["-------------------------------------------\nTime: 2023-07-09 22:39:00\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:05\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:10\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:15\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:20\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:25\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:30\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:35\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:40\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:45\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:50\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:39:55\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:00\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:05\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:10\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:15\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:20\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:25\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:30\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:35\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:40\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:45\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:50\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:40:55\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:00\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:05\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:10\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:15\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:20\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:25\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:30\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:35\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:40\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:45\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:50\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:41:55\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:00\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:05\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:10\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:15\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:20\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:25\n-------------------------------------------\n('', 1)\n('mensaje1', 1)\n\n-------------------------------------------\nTime: 2023-07-09 22:42:30\n-------------------------------------------\n('mensaje2', 1)\n\n-------------------------------------------\nTime: 2023-07-09 22:42:35\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:40\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:45\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:42:50\n-------------------------------------------\n('mensaje3', 1)\n\n-------------------------------------------\nTime: 2023-07-09 22:42:55\n-------------------------------------------\n('mensaje', 3)\n\n-------------------------------------------\nTime: 2023-07-09 22:43:00\n-------------------------------------------\n('mensaje', 1)\n\n-------------------------------------------\nTime: 2023-07-09 22:43:05\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:43:10\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:43:15\n-------------------------------------------\n\n-------------------------------------------\nTime: 2023-07-09 22:43:20\n-------------------------------------------\n\n"]},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"StreamingSocket","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3232893737865029,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
